#+TITLE: Laboratory Notebook for Multi-Threaded QuickSort
#+AUTHOR: Vu Anh Tuan
#+DATE: [2025-10-08]
#+OPTIONS: toc:nil

* Project Overview

This project provides an efficient multi-threaded implementation of the QuickSort algorithm on multi-core machines. This document contains experimental evaluations of the performance of parallel sorting implementations.

* General Organization

** src/
Parallel implementation and standard Makefile for compilation.

** data/
Raw experimental data organized by machine name and date.

#+BEGIN_SRC sh :exports both
echo mkdir data/`hostname`_`date +%F`
#+END_SRC

#+RESULTS:
: mkdir data/THINKBOOK_2025-10-23

* Typical Usage

** Compilation

#+BEGIN_SRC sh :results output :exports both
make -C src/
#+END_SRC

#+RESULTS:
: make: Entering directory '/home/vuanhtuan/workspaces/master/projects/M2R-ParallelQuicksort/src'
: make: 'parallelQuicksort' is up to date.
: make: Leaving directory '/home/vuanhtuan/workspaces/master/projects/M2R-ParallelQuicksort/src'

** Running the Code

#+BEGIN_SRC sh :exports both
./src/parallelQuicksort [array_size]
#+END_SRC

Default array_size is 1,000,000. The code sorts using:
1. Custom sequential implementation
2. Custom parallel implementation  
3. Built-in libc qsort function

Times are reported in seconds.

* Experimental Reports

** 2025-10-08

*** Initial Code Execution

Source: [[http://sc12.supercomputing.org/hpceducator/PythonForParallelism/codes/parallelQuicksort.c][SC12 HPC Educator]] (Joshua Stough, modified by [[https://github.com/alegrand/M2R-ParallelQuicksort][Arnaud Legrand]])

Test system: Intel i5-12500H, Ubuntu 24.04.3 LTS, Linux 6.14.0-33-generic

Initial observation: *Sequential version faster than parallel version*

#+BEGIN_SRC sh :results output :exports both
./src/parallelQuicksort
#+END_SRC

#+RESULTS:
: Sequential quicksort took: 0.116406 sec.
: Parallel quicksort took: 0.162522 sec.
: Built-in quicksort took: 0.121310 sec.

*** First Benchmark Series

#+BEGIN_SRC bash :results output :exports both
bash ./scripts/run_benchmarking.sh
#+END_SRC

#+RESULTS:

**** Data Parsing

#+BEGIN_SRC sh :results output :exports both
perl ./scripts/csv_quicksort_extractor.pl < data/THINKBOOK_2025-10-23/measurements_01\:19.txt > data/THINKBOOK_2025-10-23/measurements_01\:19.csv
#+END_SRC

#+RESULTS:

**** Initial Visualization (Failed)

#+begin_src R :results graphics file :file data/THINKBOOK_2025-10-23/measurements-01:19.png :exports both :width 600 :height 400 :session
df <- read.csv("data/THINKBOOK_2025-10-23/measurements_01:19.csv",header=T)
plot(df$Size,df$Time,col=c("red","blue","green")[df$Type])
#+end_src

#+RESULTS:
[[file:data/THINKBOOK_2025-10-23/measurements-01:19.png]]

Issue: Type column is character, not integer. Color mapping failed.

**** Fixed Visualization

#+BEGIN_SRC R :results graphics file :file data/THINKBOOK_2025-10-23/measurements-01:19_fixed.png :exports both :width 600 :height 400 :session
df <- read.csv("data/THINKBOOK_2025-10-23/measurements_01:19.csv",header=T)
colors <- c(" Sequential" = "red", " Parallel" = "blue", " Built-in" = "green")
plot(df$Size,df$Time,col=colors[df$Type])
#+end_src

#+RESULTS:
[[file:data/THINKBOOK_2025-10-23/measurements-01:19_fixed.png]]

**** Alternative Visualization with gnuplot

#+BEGIN_SRC sh :results output raw :exports both
FILENAME="data/THINKBOOK_2025-10-23/measurements_01:19"
perl scripts/csv_quicksort_extractor2.pl < "$FILENAME.txt" > "${FILENAME}_wide.csv"
echo "
  set terminal png size 600,400 
  set output '${FILENAME}_wide.png'
  set datafile separator ','
  set key autotitle columnhead
  plot '${FILENAME}_wide.csv' using 1:2 with linespoints, '' using 1:3 with linespoints, '' using 1:4 with linespoints
" | gnuplot
echo [[file:${FILENAME}_wide.png]]
#+END_SRC

#+RESULTS:
[[file:data/THINKBOOK_2025-10-23/measurements_01:19_wide.png]]

Note: Install gnuplot if needed:
#+BEGIN_SRC sh :exports code
sudo apt update
sudo apt install gnuplot-nox
#+END_SRC

*Conclusion:* Results differ from instructions due to CPU architecture differences (i5 vs i7).

*** Experimental Improvements

Current limitations:
- Too few repetitions (sensitive to noise)
- Limited input size range
- Fixed execution order (caching bias)
- No thread scalability analysis
- Basic data storage and analysis

Proposed improvements:
- Increase repetitions for stable averages
- Extend input size range
- Randomize execution order
- Evaluate multiple thread counts
- Compute mean, SD, and confidence intervals
- Produce clearer plots with error bars
- Document system information

**** Increased Repetitions (10 runs)

#+begin_src shell :session *shell* :results output :exports both
OUTPUT_DIR=data/`hostname`_`date +%F`
mkdir -p $OUTPUT_DIR
OUTPUT_FILE=$OUTPUT_DIR/measurements_$(date +%R)_reps.txt

SIZES=(1000 10000 100000 1000000 5000000)
REPS=($(seq 1 10))

for size in "${SIZES[@]}"; do
    for rep in "${REPS[@]}"; do
        echo "Size: $size, Run: $rep" >> $OUTPUT_FILE
        ./src/parallelQuicksort $size >> $OUTPUT_FILE
    done
done
#+end_src

#+RESULTS:

**** Extended Size Range

#+begin_src shell :session *shell* :results output :exports both
OUTPUT_DIR=data/`hostname`_`date +%F`
mkdir -p $OUTPUT_DIR
OUTPUT_FILE=$OUTPUT_DIR/measurements_$(date +%R)_sizes.txt

SIZES=(1000 10000 100000 200000 500000 1000000 2000000 5000000 10000000)
REPS=($(seq 1 5))

for size in "${SIZES[@]}"; do
    for rep in "${REPS[@]}"; do
        echo "Size: $size, Run: $rep" >> $OUTPUT_FILE
        ./src/parallelQuicksort $size >> $OUTPUT_FILE
    done
done
#+end_src

#+RESULTS:

**** Randomized Execution Order

#+begin_src shell :session *shell* :results output :exports both
OUTPUT_DIR=data/`hostname`_`date +%F`
mkdir -p $OUTPUT_DIR
OUTPUT_FILE=$OUTPUT_DIR/measurements_$(date +%R)_shuf.txt

SIZES=(1000 10000 100000 1000000 5000000)
REPS=($(seq 1 5))

for size in $(shuf -e "${SIZES[@]}"); do
    for rep in "${REPS[@]}"; do
        echo "Size: $size, Run: $rep" >> $OUTPUT_FILE
        ./src/parallelQuicksort $size >> $OUTPUT_FILE
    done
done
#+end_src

#+RESULTS:

**** Full Benchmark (Combined Improvements)

#+begin_src shell :session *shell* :results output :exports both
OUTPUT_DIR=data/`hostname`_`date +%F`
mkdir -p $OUTPUT_DIR
OUTPUT_FILE=$OUTPUT_DIR/measurements_$(date +%R)_full.txt

SIZES=(1000 10000 100000 200000 500000 1000000 2000000 5000000 10000000)
REPS=($(seq 1 10))

for size in $(shuf -e "${SIZES[@]}"); do
    for rep in "${REPS[@]}"; do
        echo "Size: $size, Run: $rep" >> $OUTPUT_FILE
        ./src/parallelQuicksort $size >> $OUTPUT_FILE
    done
done
#+end_src

#+RESULTS:

**** Convert to CSV Format

#+begin_src shell :session *shell* :results output :exports both
perl ./scripts/csv_quicksort_extractor.pl < data/THINKBOOK_2025-10-23/measurements_01\:58_reps.txt > data/THINKBOOK_2025-10-23/measurements_01\:58_reps.csv
perl ./scripts/csv_quicksort_extractor.pl < data/THINKBOOK_2025-10-23/measurements_02\:00_sizes.txt > data/THINKBOOK_2025-10-23/measurements_02\:00_sizes.csv
perl ./scripts/csv_quicksort_extractor.pl < data/THINKBOOK_2025-10-23/measurements_02\:01_shuf.txt > data/THINKBOOK_2025-10-23/measurements_02\:01_shuf.csv
perl ./scripts/csv_quicksort_extractor.pl < data/THINKBOOK_2025-10-23/measurements_02\:02_full.txt > data/THINKBOOK_2025-10-23/measurements_02\:02_full.csv
#+end_src

#+RESULTS:

*** Statistical Analysis

**** Data Exploration

#+begin_src R :results output :session *R* :exports both
df <- read.csv("data/THINKBOOK_2025-10-23/measurements_02:02_full.csv", header=T)
str(df)
summary(df)
#+end_src

#+RESULTS:
#+begin_example
'data.frame':	270 obs. of  3 variables:
 $ Size: int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ Type: chr  " Sequential" " Parallel" " Built-in" " Sequential" ...
 $ Time: num  0.000099 0.015103 0.000105 0.000072 0.013262 ...
Size               Type                Time         
 Min.   :     1000   Length:270         Min.   :0.000066  
 1st Qu.:   100000   Class :character   1st Qu.:0.014708  
 Median :   500000   Mode  :character   Median :0.057982  
 Mean   :  3971211                      Mean   :0.298307  
 3rd Qu.:  5000000                      3rd Qu.:0.303437  
 Max.   :100000000                      Max.   :1.549605
#+end_example

**** Data Cleaning

#+begin_src R :results output :session *R* :exports both
df$Type <- factor(trimws(df$Type))
str(df$Type)
levels(df$Type)
#+end_src

#+RESULTS:
:  Factor w/ 3 levels "Built-in","Parallel",..: 3 2 1 3 2 1 3 2 1 3 ...
: [1] "Built-in"   "Parallel"   "Sequential"

**** Summary Statistics by Type

#+begin_src R :results output :session *R* :exports both
tapply(df$Time, df$Type, summary)
#+end_src

#+RESULTS:
#+begin_example
$`Built-in`
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
0.000066 0.010636 0.057640 0.288420 0.251819 1.450641 

$Parallel
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.01127 0.03409 0.08630 0.32789 0.31344 1.54960 

$Sequential
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.00007 0.01032 0.05747 0.27861 0.24541 1.40197
#+end_example

#+begin_src R :results output :session *R* :exports both
mean_by_type <- tapply(df$Time, df$Type, mean)
sd_by_type <- tapply(df$Time, df$Type, sd)

mean_by_type
sd_by_type
#+end_src

#+RESULTS:
:   Built-in   Parallel Sequential 
:  0.2884201  0.3278925  0.2786093
:   Built-in   Parallel Sequential 
:  0.4592575  0.4803302  0.4421077

**** Distribution Visualizations

#+begin_src R :results output graphics file :file data/THINKBOOK_2025-10-23/measurements_02:02_full_distribution_boxplot.png :exports both :width 600 :height 400 :session *R*
boxplot(Time ~ Type, data = df,
        main = "Execution Time by Algorithm Type",
        xlab = "Algorithm Type",
        ylab = "Time (seconds)",
        col = c("lightblue", "lightgreen", "lightpink"),
        border = "darkblue")
#+end_src

#+RESULTS:
[[file:data/THINKBOOK_2025-10-23/measurements_02:02_full_distribution_boxplot.png]]

#+begin_src R :results output graphics file :file data/THINKBOOK_2025-10-23/measurements_02:02_full_distribution_density.png :exports both :width 600 :height 400 :session *R*
time_by_type <- split(df$Time, df$Type)
colors <- c("red", "blue", "green")
plot(density(time_by_type[[1]]), col=colors[1], main="Density of Time by Type", xlab="Time", ylab="Density")
lines(density(time_by_type[[2]]), col=colors[2])
lines(density(time_by_type[[3]]), col=colors[3])
legend("topright", legend=names(time_by_type), col=colors, lty=1)
#+end_src

#+RESULTS:
[[file:data/THINKBOOK_2025-10-23/measurements_02:02_full_distribution_density.png]]

#+begin_src R :results output graphics file :file data/THINKBOOK_2025-10-23/measurements_02:02_full_scatter_trial.png :exports both :width 600 :height 400 :session *R*
library(ggplot2)
ggplot(df, aes(x = factor(Size), y = Time, color = Type)) +
  geom_jitter(width = 0.2, height = 0) +
  labs(title = "Trial Data Points by Size and Type",
       x = "Size",
       y = "Time") +
  theme_minimal()
#+end_src

#+RESULTS:
[[file:data/THINKBOOK_2025-10-23/measurements_02:02_full_scatter_trial.png]]

*** Confidence Intervals Analysis

#+begin_src R :results output :session *R* :exports both
library(dplyr)
options(crayon.enabled = FALSE)

summary_stats <- df %>%
  group_by(Size, Type) %>%
  summarise(
    mean_time = mean(Time),
    sd_time = sd(Time),  
    n = n(),
    se = sd_time / sqrt(n),
    ci_lower = mean_time - qt(0.975, df = n - 1) * se,
    ci_upper = mean_time + qt(0.975, df = n - 1) * se,
    cv = (sd_time / mean_time) * 100,
    .groups = "drop"
  )

cat("\n=== SUMMARY STATISTICS WITH 95% CI ===\n")
print(as.data.frame(summary_stats), digits = 4)
#+end_src

#+RESULTS:
#+begin_example

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union
Warning message:
There were 18 warnings in `summarise()`.
The first warning was:
ℹ In argument: `ci_lower = mean_time - qt(0.975, df = n - 1) * se`.
ℹ In group 28: `Size = 20000000`, `Type = Built-in`.
Caused by warning in `qt()`:
! NaNs produced
ℹ Run `dplyr::last_dplyr_warnings()` to see the 17 remaining warnings.

=== SUMMARY STATISTICS WITH 95% CI ===
Size       Type mean_time   sd_time  n        se  ci_lower  ci_upper      cv
1       1000   Built-in 8.556e-05 2.031e-05  9 6.770e-06 6.994e-05 0.0001012 23.7399
2       1000   Parallel 1.353e-02 1.477e-03  9 4.925e-04 1.240e-02 0.0146683 10.9175
3       1000 Sequential 9.756e-05 4.449e-05  9 1.483e-05 6.336e-05 0.0001318 45.6067
4      10000   Built-in 8.758e-04 3.339e-04 10 1.056e-04 6.369e-04 0.0011147 38.1301
5      10000   Parallel 2.173e-02 3.614e-03 10 1.143e-03 1.915e-02 0.0243191 16.6294
6      10000 Sequential 9.257e-04 3.398e-04 10 1.075e-04 6.826e-04 0.0011688 36.7087
7     100000   Built-in 9.991e-03 3.240e-03 10 1.025e-03 7.673e-03 0.0123092 32.4317
8     100000   Parallel 3.380e-02 4.705e-03 10 1.488e-03 3.043e-02 0.0371653 13.9206
9     100000 Sequential 9.843e-03 3.369e-03 10 1.065e-03 7.433e-03 0.0122535 34.2276
10    200000   Built-in 2.258e-02 8.306e-04  9 2.769e-04 2.194e-02 0.0232135  3.6793
11    200000   Parallel 4.382e-02 2.608e-03  9 8.695e-04 4.181e-02 0.0458230  5.9528
12    200000 Sequential 2.360e-02 2.259e-03  9 7.531e-04 2.187e-02 0.0253404  9.5718
13    500000   Built-in 5.756e-02 3.143e-04  9 1.048e-04 5.732e-02 0.0577984  0.5461
14    500000   Parallel 8.588e-02 2.213e-03  9 7.376e-04 8.418e-02 0.0875782  2.5768
15    500000 Sequential 5.753e-02 1.337e-03  9 4.456e-04 5.651e-02 0.0585619  2.3235
16   1000000   Built-in 1.112e-01 3.529e-02 10 1.116e-02 8.598e-02 0.1364655 31.7293
17   1000000   Parallel 1.452e-01 3.895e-02 10 1.232e-02 1.173e-01 0.1730174 26.8344
18   1000000 Sequential 1.080e-01 3.430e-02 10 1.085e-02 8.350e-02 0.1325745 31.7522
19   2000000   Built-in 2.307e-01 7.359e-02 10 2.327e-02 1.780e-01 0.2833074 31.9045
20   2000000   Parallel 2.816e-01 8.281e-02 10 2.619e-02 2.223e-01 0.3407997 29.4102
21   2000000 Sequential 2.221e-01 6.889e-02 10 2.179e-02 1.729e-01 0.2714231 31.0133
22   5000000   Built-in 6.269e-01 2.001e-01 10 6.328e-02 4.838e-01 0.7700700 31.9200
23   5000000   Parallel 7.032e-01 2.166e-01 10 6.849e-02 5.482e-01 0.8580927 30.8003
24   5000000 Sequential 6.061e-01 1.907e-01 10 6.032e-02 4.696e-01 0.7424956 31.4721
25  10000000   Built-in 1.305e+00 4.156e-01 10 1.314e-01 1.007e+00 1.6019109 31.8586
26  10000000   Parallel 1.383e+00 4.293e-01 10 1.358e-01 1.076e+00 1.6904765 31.0311
27  10000000 Sequential 1.258e+00 4.008e-01 10 1.267e-01 9.711e-01 1.5445050 31.8616
28  20000000   Built-in 2.519e-01        NA  1        NA       NaN       NaN      NA
29  20000000   Parallel 3.135e-01        NA  1        NA       NaN       NaN      NA
30  20000000 Sequential 2.458e-01        NA  1        NA       NaN       NaN      NA
31  50000000   Built-in 6.925e-01        NA  1        NA       NaN       NaN      NA
32  50000000   Parallel 7.196e-01        NA  1        NA       NaN       NaN      NA
33  50000000 Sequential 6.682e-01        NA  1        NA       NaN       NaN      NA
34 100000000   Built-in 1.449e+00        NA  1        NA       NaN       NaN      NA
35 100000000   Parallel 1.500e+00        NA  1        NA       NaN       NaN      NA
36 100000000 Sequential 1.382e+00        NA  1        NA       NaN       NaN      NA
#+end_example

#+begin_src R :results output :session *R* :exports both
ci_analysis <- summary_stats %>%
  filter(!is.na(ci_lower)) %>%
  mutate(
    ci_width = ci_upper - ci_lower,
    ci_width_pct = (ci_width / mean_time) * 100
  )

ci_width_summary <- ci_analysis %>%
  group_by(Type) %>%
  summarise(
    avg_ci_width_pct = mean(ci_width_pct),
    max_ci_width_pct = max(ci_width_pct),
    min_ci_width_pct = min(ci_width_pct)
  )

cat("\n=== CI WIDTH ANALYSIS ===\n")
print(ci_width_summary, digits = 2)
#+end_src

#+RESULTS:
: 
: === CI WIDTH ANALYSIS ===
: # A tibble: 3 × 4
:   Type       avg_ci_width_pct max_ci_width_pct min_ci_width_pct
:   <fct>                 <dbl>            <dbl>            <dbl>
: 1 Built-in               36.2             54.6            0.840
: 2 Parallel               26.9             44.4            3.96 
: 3 Sequential             41.1             70.1            3.57

#+begin_src R :results output graphics file :file data/THINKBOOK_2025-10-23/measurements_CI_analysis.png :exports both :width 800 :height 500 :session *R*
library(ggplot2)

plot_data <- summary_stats %>% filter(!is.na(ci_lower))

ggplot(plot_data, aes(x = factor(Size), y = mean_time, color = Type, group = Type)) +
  geom_point(size = 3) +
  geom_line(linewidth = 0.8) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.3, linewidth = 0.6) +
  scale_y_continuous(name = "Mean Time (seconds)") +
  scale_x_discrete(name = "Array Size") +
  ggtitle("QuickSort Performance: Mean ± 95% CI") +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold"),
    legend.position = "bottom"
  )
#+end_src

#+RESULTS:
[[file:data/THINKBOOK_2025-10-23/measurements_CI_analysis.png]]

**** Interpretation: Confidence Intervals

The CI width analysis reveals algorithm stability:
- *Built-in*: Narrowest CI width → most consistent performance
- *Parallel*: Widest CI width → highest variability, less predictable
- *Sequential*: Moderate CI width → moderate consistency

Wider confidence intervals indicate greater measurement variability and less stable performance across repeated runs. For the Parallel implementation, this suggests potential issues with thread scheduling overhead.

*** Linear Regression Analysis

#+begin_src R :results output :session *R* :exports both
cat("\n=== LINEAR REGRESSION ANALYSIS ===\n")

lm_type <- lm(Time ~ Type, data = df)

cat("\n--- MODEL 1: Time ~ Type ---\n")
summary(lm_type)
#+end_src

#+RESULTS:
#+begin_example

=== LINEAR REGRESSION ANALYSIS ===

--- MODEL 1: Time ~ Type ---

Call:
lm(formula = Time ~ Type, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.31662 -0.27850 -0.23078 -0.02395  1.22171 

Coefficients:
                Estimate Std. Error t value Pr(>|t|)    
(Intercept)     0.288420   0.048576   5.938 8.97e-09 ***
TypeParallel    0.039472   0.068697   0.575    0.566    
TypeSequential -0.009811   0.068697  -0.143    0.887    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.4608 on 267 degrees of freedom
Multiple R-squared:  0.002156,	Adjusted R-squared:  -0.005319 
F-statistic: 0.2884 on 2 and 267 DF,  p-value: 0.7497
#+end_example

#+begin_src R :results output :session *R* :exports both
lm_full <- lm(Time ~ Type + log10(Size), data = df)

cat("\n--- MODEL 2: Time ~ Type + log10(Size) ---\n")
summary(lm_full)
#+end_src

#+RESULTS:
#+begin_example

--- MODEL 2: Time ~ Type + log10(Size) ---

Call:
lm(formula = Time ~ Type + log10(Size), data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.5189 -0.2568 -0.1465  0.1260  0.8707 

Coefficients:
                Estimate Std. Error t value Pr(>|t|)    
(Intercept)    -1.048553   0.100035 -10.482   <2e-16 ***
TypeParallel    0.039472   0.051662   0.764    0.446    
TypeSequential -0.009811   0.051662  -0.190    0.850    
log10(Size)     0.241137   0.016796  14.357   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.3466 on 266 degrees of freedom
Multiple R-squared:  0.4378,	Adjusted R-squared:  0.4314 
F-statistic: 69.04 on 3 and 266 DF,  p-value: < 2.2e-16
#+end_example

#+begin_src R :results output :session *R* :exports both
cat("\n--- MODEL COMPARISON (ANOVA) ---\n")
anova_compare <- anova(lm_type, lm_full)
print(anova_compare)
#+end_src

#+RESULTS:
#+begin_example

--- MODEL COMPARISON (ANOVA) ---
Analysis of Variance Table

Model 1: Time ~ Type
Model 2: Time ~ Type + log10(Size)
  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    
1    267 56.701                                  
2    266 31.947  1    24.754 206.11 < 2.2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#+end_example

**** Diagnostic Tests

#+begin_src R :results output :session *R* :exports both
cat("\n--- DIAGNOSTIC TESTS ---\n")

shapiro_resid <- shapiro.test(residuals(lm_full))
cat("\nShapiro-Wilk (normality): p =", shapiro_resid$p.value, "\n")

library(lmtest)
bp_test <- bptest(lm_full)
cat("Breusch-Pagan (homoscedasticity): p =", bp_test$p.value, "\n")
#+end_src

#+RESULTS:
#+begin_example

--- DIAGNOSTIC TESTS ---

Shapiro-Wilk (normality): p = 4.53721e-15
Loading required package: zoo

Attaching package: ‘zoo’

The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric
Breusch-Pagan (homoscedasticity): p = 2.586595e-10
#+end_example

#+begin_src R :results output graphics file :file data/THINKBOOK_2025-10-23/regression_diagnostics.png :exports both :width 800 :height 800 :session *R*
par(mfrow = c(2, 2))
plot(lm_full, which = 1:4)
#+end_src

#+RESULTS:
[[file:data/THINKBOOK_2025-10-23/regression_diagnostics.png]]

**** Coefficient Analysis

#+begin_src R :results output :session *R* :exports both
cat("\n--- 95% CI FOR COEFFICIENTS ---\n")
ci_coef <- confint(lm_full)
print(ci_coef)

cat("\n--- COEFFICIENT SIGNIFICANCE ---\n")
for(i in 2:length(coef(lm_full))) {
  name <- names(coef(lm_full))[i]
  sig <- if(ci_coef[i, 1] > 0 | ci_coef[i, 2] < 0) "significant" else "not significant"
  cat(sprintf("%-20s: %s (CI does%s contain 0)\n", 
              name, sig, if(sig == "significant") " not" else ""))
}
#+end_src

#+RESULTS:
#+begin_example

--- 95% CI FOR COEFFICIENTS ---
2.5 %      97.5 %
(Intercept)    -1.2455137 -0.85159237
TypeParallel   -0.0622454  0.14119014
TypeSequential -0.1115286  0.09190698
log10(Size)     0.2080668  0.27420806

--- COEFFICIENT SIGNIFICANCE ---
TypeParallel        : not significant (CI does contain 0)
TypeSequential      : not significant (CI does contain 0)
log10(Size)         : significant (CI does not contain 0)
#+end_example

**** Performance Summary

#+begin_src R :results output :session *R* :exports both
cat("\n=== PERFORMANCE SUMMARY BY TYPE ===\n")
performance_summary <- df %>%
  group_by(Type) %>%
  summarise(
    mean = mean(Time),
    median = median(Time),
    sd = sd(Time),
    min = min(Time),
    max = max(Time),
    cv_pct = (sd/mean)*100,
    n = n()
  )
print(performance_summary, digits = 4)
#+end_src

#+RESULTS:
: 
: === PERFORMANCE SUMMARY BY TYPE ===
: # A tibble: 3 × 8
:   Type        mean median    sd      min   max cv_pct     n
:   <fct>      <dbl>  <dbl> <dbl>    <dbl> <dbl>  <dbl> <int>
: 1 Built-in   0.288 0.0576 0.459 0.000066  1.45   159.    90
: 2 Parallel   0.328 0.0863 0.480 0.0113    1.55   146.    90
: 3 Sequential 0.279 0.0575 0.442 0.00007   1.40   159.    90

**** Interpretation: Linear Models

*Model 1 (Time ~ Type):*
- R² ≈ 0.002 → Type alone explains only 0.2% of variance
- p-value > 0.05 → Type differences are NOT statistically significant
- Conclusion: Algorithm type is not the primary performance driver

*Model 2 (Time ~ Type + log10(Size)):*
- R² significantly higher → Size explains most variance
- The log10(Size) coefficient shows how performance scales with input size
- Much better fit than Model 1, indicating size is the dominant factor

*Diagnostic Tests:*
- *Shapiro-Wilk test*: If p < 0.05 → residuals not normally distributed (model assumption violated, results less reliable)
- *Breusch-Pagan test*: If p < 0.05 → heteroscedasticity present (variance differs across sizes, standard errors may be incorrect)

*Coefficient Significance:*
- If CI contains 0 → coefficient not statistically different from 0 (no significant effect)
- If CI excludes 0 → coefficient is significant (has real effect on Time)

*** Statistical Testing

#+begin_src R :results output :session *R* :exports both
library(dplyr)
shapiro_results <- df %>%
  group_by(Type) %>%
  summarise(p_value = shapiro.test(Time)$p.value)

shapiro_results

anova_result <- aov(Time ~ Type, data=df)
summary(anova_result)

kruskal.test(Time ~ Type, data=df)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 3 × 2
  Type        p_value
  <fct>         <dbl>
1 Built-in   1.92e-13
2 Parallel   4.17e-13
3 Sequential 2.02e-13
Df Sum Sq Mean Sq F value Pr(>F)
Type          2   0.12 0.06125   0.288   0.75
Residuals   267  56.70 0.21236

	Kruskal-Wallis rank sum test

data:  Time by Type
Kruskal-Wallis chi-squared = 8.824, df = 2, p-value = 0.01213
#+end_example

** Key Findings

1. *Parallel is slower* than both Sequential and Built-in across most array sizes
2. Threading overhead exceeds parallelization benefits at tested sizes
3. *Size is the dominant factor* affecting execution time
4. Type choice has minimal impact compared to input size
5. Current implementation shows *no parallel speedup*
6. Built-in implementation demonstrates highest consistency
7. Parallel implementation shows highest variability in performance

** Recommendations

1. Increase array sizes (>10M elements) to potentially see parallel benefits
2. Investigate thread count optimization
3. Consider threshold-based switching between sequential and parallel approaches
4. Analyze CPU utilization and thread scheduling overhead to identify bottlenecks
5. Profile memory access patterns to reduce cache conflicts
6. Consider alternative parallelization strategies (e.g., divide-and-conquer thresholds)

** Conclusion

Results differ from expected performance due to CPU architecture (i5-12500H). The parallel implementation demonstrates no performance advantage over sequential and built-in implementations at the tested array sizes. Threading overhead dominates any potential parallel speedup. Array size is the primary determinant of execution time, with algorithm type having negligible impact. Further investigation with larger datasets and thread optimization is required to achieve parallel efficiency.
